{% extends "base.html" %} {% block content %}

<div class="container">
  <div
    class="jumbotron"
    style="
      background-color: #f7f7f7;
      border-style: solid;
      border-color: #cac9c9;
      border-width: 1px;
    "
  >
    <h1 class="display-4">Wie funktioniert das hier?</h1>
    <p class="lead">Und überhaupt: Wozu das ganze?</p>

    <hr class="my-4" />
    <p>
      Erfahre auf dieser Seite alles über die eingesetzten Scraper, über JSONS,
      Daten-Visualisierung und Code.
      <br />
      Inspiriert wurde diese Seite von
      <a href="https://heisse-preise.io/" target="_blank">heisse-preise.io</a> [
      <a
        href="https://github.com/badlogic/heissepreise/tree/main"
        target="_blank"
        >GitHub</a
      >
      ], die für den österreichischen Markt Analysen durchführt.
    </p>
  </div>

  <div class="card mt-4">
    <div class="card-header bg-warning">
      <strong>
        <i class="icon-question icon-2x"></i>&nbsp;Woher kommen die
        Daten?</strong
      >
    </div>
    <div class="card-body">
      <p>
        Die Daten und Preise sind frei in den Online-Shops zugänglich. Wenn man
        z.B. die Seite:
        <br /><br />
        <code
          ><a href="https://www.kaufland.de/item/search/?search_value=kartoffel"
            >https://www.kaufland.de/item/search/?search_value=kartoffel</a
          ></code
        >
        <br />
        <br />
        aufruft, erhält man viele Artikel zum Suchwort <em>Kartoffel</em>. Mit
        automatisierten Scripts kann man den Quellcode dieser Website auslesen
        und die Preise auslesen. (Versuch es selbst und lass dir mit einem
        Rechtsklick auf die Website den Seiten-Quellcode anzeigen).
        <br />
        <br />
        Eine andere Methode ist der Daten-Abruf via <strong>API</strong>.
        <br />
        Versuch es selbst: Mit dem Link
        <br />
        <br />

        <code>
          <a href="https://www.lidl.de/p/api/gridboxes/DE/de/?max=1"
            >https://www.lidl.de/p/api/gridboxes/DE/de/?max=1</a
          >
        </code>

        <br />
        <br />

        kannst du dir einen Artikel aus dem LIDL-Onlineshop aufrufen.
        <br />
        Sieht erstmal kryptisch aus, aber bei genauerem Betrachten entdeckst du
        den Titel, Produktbeschreibungen, den Link zum Produktbild und den
        Preis.
        <br />
        All das lesen meine automatisierten Skripte aus und speichern es
        übersichtlich ab - natürlich für mehr als nur ein Produkt.
      </p>

      <div class="d-flex flex-row-reverse align-items-baseline">
        <a
          class="btn btn-secondary"
          href="https://github.com/SebastianChristoph/preischeck"
          target="_blank"
          >Hier geht's zur GIT-Repo</a
        >
        <p class="mr-4"><strong>Du möchtest dir den Code ansehen?</strong></p>
      </div>
    </div>
  </div>

  <div class="card mt-4">
    <div class="card-header bg-warning">
      <strong
        ><i class="icon-question icon-2x"></i>&nbsp;Wozu das ganze?</strong
      >
    </div>
    <div class="card-body">
      <p>
        Die tägliche Durchforstung der Online-Shops deutscher Supermärkte und
        die Speicherung von Preisen von über 15.000 Artikel dienen einem
        speziellen Zweck: die transparente Preisentwicklung und Trends sichtbar
        zu machen.
      </p>
      <p>
        Die Seite erfasst kontinuierlich die Preise verschiedener Produkte mit
        Hilfe von <strong>WebScraping</strong> und zeigt, wie sie sich über die
        Zeit hinweg verändert haben. Dies ermöglicht es, Preistrends zu erkennen
        und zu verstehen, ob ein Produkt tendenziell teurer oder günstiger wird.
      </p>
      <p>
        <strong>Trendanalyse</strong>: Die Daten ermöglichen es auch, allgemeine
        Trends in den Preisen bestimmter Produktkategorien zu identifizieren.
        Dies kann nützlich sein, um sich auf saisonale Schwankungen oder
        Markttrends vorzubereiten.
      </p>
      <p>
        <strong>Langfristige Planung</strong>: Wenn du Produkte regelmäßig
        kaufst, hilft dir die Transparenz der Preisentwicklung dabei,
        langfristige Budgets und Einkaufsstrategien zu entwickeln. Du kannst
        besser einschätzen, wie sich die Kosten für deine regelmäßigen Einkäufe
        im Laufe der Zeit ändern.
      </p>
      <p>
        Insgesamt zielt die Seite darauf ab, dir die Informationen zu liefern,
        die du benötigst, um fundierte Entscheidungen über deine Einkäufe zu
        treffen und die Preisentwicklung von Produkten besser zu verstehen. Die
        Transparenz in Bezug auf Preistrends bildet die Grundlage für kluges
        Einkaufen.
      </p>
    </div>
  </div>

  <div class="card mt-4">
    <div class="card-header bg-warning">
      <strong><i class="icon-bug icon-2x"></i>&nbsp;Web-Scraping</strong>
    </div>
    <div class="card-body">
      <p>
        Web-Scraping ist eine automatisierte Methode zum Extrahieren von
        Informationen von Websites. Ich nutze dazu Pythons Module: <br />

        <code>bs4 BeautifulSoup</code> und <code>requests</code>. Durch den
        Zugriff auf die APIs oder URLS der Online-Shops ist es möglich, alle
        möglichen Daten zu erhalten.
        <br />
        <br />
        Diese werden in einem Python Script sortiert und am Ende in einer
        JSON-Datei gespeichert - und das täglich.

        <br>
        <br>

        <img
          src="{{ url_for('static', filename='scraper.png') }}"
          class="img-fluid"
        />

        <div class="d-flex flex-row-reverse">
          <small><em>Screenshot der täglich ausgeführten Scripts</em></small>
        </div>
       
        <br />
        <br />

        Die JSON, die nach dem Ordnen der Daten entsteht, sieht pro Supermarkt so aus:
        <br />
        <br />
        <code
          >{ <br /><strong>"store"</strong>: "LIDL", <br /><strong
            >"products"</strong
          >: [ <br br />
          {"name": "Original Irische Butter" <br />"category": "Molkerei",
          <br />"imageURL": "www....", <br />"original_link": "www..",
          <br />"found_by_keyword": "Butter", <br />"dates": { <br />
          "02-10-2023": 9.56,
          <br />
          "03-10-2023": 9.56, <br />
          "04-10-2023": 9.57 } <br />
          }, <br /><br />
          { "name": "Chips", <br />
          "category": "Snacks",
          <br />"imageURL": "www....", <br />"original_link": "www..",
          <br />"found_by_keyword": "Butter", <br />
          "dates": {
          <br />
          "02-10-2023": 5.56, <br />
          "03-10-2023": 5.56,
          <br />
          "04-10-2023": 5.57 }, <br />
          } <br />
          ... <br />
          &nbsp;&nbsp;] <br />
          }
        </code>

        <br />
        <br />

        Die Hauptaufgabe von Web-Scraping besteht darin, Daten von Webseiten zu
        sammeln und in einer strukturierten Form zu speichern, die für weitere
        Analysen oder Anwendungen verwendet werden kann.
      </p>
      <div class="d-flex flex-row-reverse align-items-baseline">
        <a
          class="btn btn-secondary"
          href="https://github.com/SebastianChristoph/preischeck"
          >Hier geht's zur GIT-Repo</a
        >
        <p class="mr-4"><strong>Du möchtest dir den Code anschauen?</strong></p>
      </div>
      <p>Hier folgt bald auch noch die die Arbeitsweise der Scraper.</p>
    </div>
  </div>

  <div class="card mt-4">
    <div class="card-header bg-warning">
      <strong
        ><i class="icon-bar-chart icon-2x"></i>&nbsp;Visualisierung</strong
      >
    </div>
    <div class="card-body">
      <p>
        Die Visualisierung der Daten erfolgt auf effektive und ansprechende
        Weise, um dir wertvolle Einblicke in die Preisentwicklung und Trends zu
        bieten. Dabei setzt die Seite auf das leistungsstarke Tool
        <strong>Chart.js</strong> und nutzt eine JSON-basierte Datenstruktur, um
        die Grafiken und Diagramme zu erstellen.
      </p>
      <br />
      <p>
        <strong>Datenaggregation:</strong> Zuerst werden kontinuierlich Daten
        durch die WebCrawling-Automatisierung gesammelt. Diese Daten umfassen
        Preise, Zeitstempel und andere relevante Informationen.
      </p>
      <br />
      <p>
        <strong>Datenverarbeitung:</strong> Die gesammelten Daten werden dann
        aufbereitet und in einer JSON-Datei strukturiert. Diese JSON-Datei dient
        als Rohmaterial für die Visualisierungen.
      </p>
      <br />
      <p>
        <strong>Diagramme und Grafiken:</strong> Mithilfe von Chart.js werden
        interaktive Diagramme und Grafiken erstellt, die auf den gesammelten
        Daten basieren. Diese Diagramme können verschiedene Darstellungsformen
        wie Liniendiagramme, Balkendiagramme oder Tortendiagramme umfassen, je
        nachdem, welche Art der Datenvisualisierung am besten geeignet ist, um
        Trends und Entwicklungen zu verdeutlichen.
      </p>
      <br />
      <p>
        <strong>Benutzerfreundlichkeit: </strong>Die Seite bemüht sich, die
        Visualisierungen benutzerfreundlich und leicht verständlich zu
        gestalten. Dies ermöglicht es dir, die Daten schnell zu erfassen und die
        gewünschten Einblicke zu gewinnen.
      </p>
      <br />
      <p>
        Das Ziel ist es, dir eine intuitive und informative Plattform zu bieten,
        auf der du die Preisentwicklung und Trends auf einen Blick erfassen
        kannst. Die Visualisierung der Daten ermöglicht es dir, fundierte
        Entscheidungen zu treffen und das Beste aus deinem Einkaufserlebnis
        herauszuholen.
      </p>
    </div>
  </div>

  <!-- Ende container-->
</div>

{% endblock content %}
